# URPC2020

```latex
@inproceedings{liu2021dataset,
  title={A dataset and benchmark of underwater object detection for robot picking},
  author={Liu, Chongwei and Li, Haojie and Wang, Shuchang and Zhu, Ming and Wang, Dong and Fan, Xin and Wang, Zhihui},
  booktitle={2021 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}
```

The dataset contains 5,543 underwater images for training, 800 and 1,200 underwater images for testing (test-A and test-B set), covering four categories: holothurian, echinus, scallop, and starfish.

## Download URPC2020 Dataset

The Underwater Robot Professional Contest (URPC) 2020 dataset, including training set, test-A set, and test-B set from [here](https://openi.pcl.ac.cn/OpenOrcinus_orca/URPC_opticalimage_dataset/datasets). You can also download the processed data from [here](https://drive.google.com/file/d/1PgP7gY1FkcpQ1D6XW_lPzTYCgsMhItbw/view?usp=sharing).

For validation, we randomly divides the URPC2020 training set into training and validation groups with 4,434 and 1,019 images, respectively. If users want to divide by their own, `tools/misc/write_txt.py` should be used to split the train and val set first.
Then `tools/dataset_converters/xml_to_json.py` can use to convert xml style annotations to coco format.

The data structure is as follows:

```text
lqit
├── lqit
├── tools
├── configs
├── data
│   ├── URPC
│   │   ├── annotations_json       # coco style annotations
│   │   │   ├── train.json         # training group from training set, with 4,434 images
│   │   │   ├── val.json           # validation group from training set, with 1,019 images
│   │   │   ├── train_all.json     # training set, with all 5,543 images
│   │   │   ├── test-A.json        # testing-A set, with 800 images
│   │   │   ├── test-B.json        # testing-B set, with 1,200 images
│   │   │   ├── train-image        # training images
│   │   │   │   ├── 000001.jpg
│   │   │   │   ├── 000002.jpg
│   │   │   │   ├── ...
│   │   │   ├── test-A-image       # test-A images
│   │   │   │   ├── 000001.jpg
│   │   │   │   ├── 000002.jpg
│   │   │   │   ├── ...
│   │   │   ├── test-B-image       # test-B images
│   │   │   │   ├── 000001.jpg
│   │   │   │   ├── 000002.jpg
│   │   │   │   ├── ...
|   |   ├── source_data            # source data download from https://openi.pcl.ac.cn/OpenOrcinus_orca/URPC_opticalimage_dataset/datasets
│   │   │   ├── ImageSets          # get training, vaidation, testing image name from scripts
│   │   │   │   ├── train.txt
│   │   │   │   ├── val.txt
│   │   │   │   ├── train_all.txt
│   │   │   │   ├── test-A.txt
│   │   │   │   ├── test-B.txt
│   │   │   ├── ImageMetas         # get image meta information from scripts
│   │   │   │   ├── train-image-metas.pkl
│   │   │   │   ├── val-image-metas.pkl
│   │   │   │   ├── train_all-image-metas.pkl
│   │   │   │   ├── test-A-image-metas.pkl
│   │   │   │   ├── test-B-image-metas.pkl
│   │   │   ├── train-box          # pascal voc style annotations for the training set
│   │   │   │   ├── 000001.xml
│   │   │   │   ├── 000002.xml
│   │   │   │   ├── ...
│   │   │   ├── test-A-box         # pascal voc style annotations for the test-A set
│   │   │   │   ├── 000001.xml
│   │   │   │   ├── 000002.xml
│   │   │   │   ├── ...
│   │   │   ├── test-B-box         # pascal voc style annotations for the test-B set
│   │   │   │   ├── 000001.xml
│   │   │   │   ├── 000002.xml
│   │   │   │   ├── ...

```
